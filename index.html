<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AI Legal Aid Assistant ‚Äî Frontend</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>üáÆüá≥ AI Legal Aid Assistant</header>

  <div class="container">
    <label>Select Language</label>
    <select id="language">
      <option value="en">English</option>
      <option value="hi">Hindi</option>
      <option value="kn">Kannada</option>
      <option value="te">Telugu</option>
    </select>

    <label>Describe your legal issue</label>
    <textarea id="userQuery" rows="5" placeholder="Example: ‡§Æ‡•á‡§∞‡§æ ‡§ú‡§Æ‡•Ä‡§® ‡§ï‡§æ ‡§ù‡§ó‡§°‡§º‡§æ ‡§π‡•à..."></textarea>

    <button class="mic-btn" id="micBtn" title="Speak">üé§</button>

    <label>Upload Document / Image (photo of papers, FIR, land doc)</label>
    <input type="file" id="uploadImage" accept="image/*,application/pdf" multiple>

    <label>Enable Voice Assistant</label>
    <select id="voiceOption">
      <option value="off">Off</option>
      <option value="on">On</option>
    </select>

    <div class="actions">
      <button id="sendBtn">Ask Lawyer AI</button>
      <button id="clearBtn" class="muted">Clear</button>
    </div>

    <div id="responseBox" aria-live="polite"></div>
    <div id="uploadsPreview" class="preview"></div>
  </div>

<script>
/* ----------------------
   Speech-to-text (microphone)
   ---------------------- */
const micBtn = document.getElementById('micBtn');
const queryBox = document.getElementById('userQuery');
let recognition = null;

if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  recognition = new SR();
  recognition.continuous = false;
  recognition.interimResults = false;
  recognition.lang = 'hi-IN'; // default; will change based on selector
  recognition.onstart = () => micBtn.classList.add('active');
  recognition.onend = () => micBtn.classList.remove('active');
  recognition.onresult = (e) => {
    const text = e.results[0][0].transcript;
    // append to any existing content to allow multi-turn input
    queryBox.value = queryBox.value ? (queryBox.value + ' ' + text) : text;
  };
} else {
  micBtn.title = 'Voice input not supported by this browser';
  micBtn.style.opacity = '0.6';
}

micBtn.addEventListener('click', () => {
  if (!recognition) { alert('Voice input not supported on this browser. Use Chrome/Edge on desktop or Android.'); return; }
  const lang = document.getElementById('language').value;
  recognition.lang = (lang === 'en') ? 'en-IN' : (lang + '-IN');
  try { recognition.start(); } catch (e) { /* sometimes start throws if clicked repeatedly */ }
});

/* ----------------------
   Preview uploaded files
   ---------------------- */
const uploadInput = document.getElementById('uploadImage');
const uploadsPreview = document.getElementById('uploadsPreview');

uploadInput.addEventListener('change', () => {
  uploadsPreview.innerHTML = '';
  Array.from(uploadInput.files).forEach((file, i) => {
    const div = document.createElement('div');
    div.className = 'file-item';
    const name = document.createElement('div');
    name.textContent = `${file.name} (${Math.round(file.size/1024)} KB)`;
    div.appendChild(name);
    uploadsPreview.appendChild(div);
  });
});

/* ----------------------
   Send data to backend
   ---------------------- */
const sendBtn = document.getElementById('sendBtn');
const responseBox = document.getElementById('responseBox');
const voiceOption = document.getElementById('voiceOption');
const clearBtn = document.getElementById('clearBtn');

clearBtn.addEventListener('click', () => {
  queryBox.value = '';
  uploadInput.value = '';
  uploadsPreview.innerHTML = '';
  responseBox.style.display = 'none';
  responseBox.innerHTML = '';
});

sendBtn.addEventListener('click', sendQuery);

async function sendQuery() {
  const question = queryBox.value.trim();
  const language = document.getElementById('language').value;
  const voice = voiceOption.value;

  if (!question && uploadInput.files.length === 0) {
    alert('Please enter your issue or upload a document/photo.');
    return;
  }

  responseBox.style.display = 'block';
  responseBox.innerHTML = '<div class="muted">‚è≥ Processing ‚Äî please wait...</div>';

  // Build form data including files
  const form = new FormData();
  form.append('question', question);
  form.append('language', language);
  form.append('voice', voice);
  for (const f of uploadInput.files) form.append('files', f); // multiple files field name 'files'

  try {
    const res = await fetch('http://127.0.0.1:5000/api/legal', {
      method: 'POST',
      body: form
    });

    if (!res.ok) throw new Error('Server error ' + res.status);
    const data = await res.json();

    // Show response
    responseBox.innerHTML = `<div class="answer-title">AI Assistant says:</div><div class="answer-text">${escapeHtml(data.answer)}</div>`;

    // Speak if enabled
    if (voice === 'on' && 'speechSynthesis' in window) {
      const utter = new SpeechSynthesisUtterance(data.answer);
      utter.lang = (language==='hi')?'hi-IN':(language==='kn')?'kn-IN':(language==='te')?'te-IN':'en-IN';
      // optional: slower for easier listening in rural areas
      utter.rate = 0.95;
      window.speechSynthesis.cancel(); // stop previous
      window.speechSynthesis.speak(utter);
    }
  } catch (err) {
    responseBox.innerHTML = `<div class="error">‚ö†Ô∏è Error: ${escapeHtml(err.message)}</div>`;
  }
}

// small helper to escape HTML when injecting text
function escapeHtml(str) {
  if (!str) return '';
  return str.replaceAll('&','&amp;').replaceAll('<','&lt;').replaceAll('>','&gt;').replaceAll('"','&quot;');
}

</script>
</body>
</html>
